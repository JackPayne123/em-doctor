# %%
%load_ext autoreload
%autoreload 2

# %%
# Imports
import sys
import os
import gc
import torch
import os
import pandas as pd
import numpy as np

# Define models and layers
from em_organism_dir.util.activation_collection import collect_hidden_states
from em_organism_dir.util.model_util import (
    load_model, clear_memory
)
from em_organism_dir.eval.util.gen_eval_util import load_paraphrases, print_responses
from em_organism_dir.util.get_probe_texts import load_alignment_data_with_str_check, load_alignment_data_with_judging
from em_organism_dir.steering.steering_util import gen_with_steering, sweep, SweepSettings
from em_organism_dir.eval.util.eval_judge import run_judge_on_csv
from em_organism_dir.steering.vector_util import layerwise_remove_vector_projection, subtract_layerwise
from em_organism_dir.vis.quadrant_plots import (
    plot_all_eval_results,
    analyze_quadrant_percentages,
    plot_misaligned_coherent_scatter_from_dir,
    get_main_eval_stats
)
from em_organism_dir.steering.vector_util import remove_vector_projection
from em_organism_dir.util.lora_util import download_lora_weights, load_lora_state_dict, extract_mlp_downproj_components
from em_organism_dir.global_variables import BASE_DIR

# %%
RANK = 32
MODEL_SIZE = '14'
FINETUNE_VERSION = '14-B-extreme-sports'

ALIGNED_MODEL_NAME = f"unsloth/Qwen2.5-14B-Instruct"
MISALIGNED_MODEL_NAME = f"annasoli/Qwen2.5-14B-Instruct_bad-medical-advice"

LAYERS = list(range(0, 48))
# LORA_LAYERS = [24]
LORA_LAYERS = list(range(0, 48))


model_id = f'q14b_bad_med_32'   # used for saving

activation_dir = f'{BASE_DIR}/em_organism_dir/steering/vectors/{model_id}'
os.makedirs(activation_dir, exist_ok=True)

# %%

# Get aligned and misaligned responses (if not already extracted)
semantic_category = 'all'       # otherwise e.g. 'gender', 'money', 'medical'

# This version uses a string check to filter categories.
# If you have run semantic judges on the response, load_alignment_data_with_judging is better
aligned_df, misaligned_df = load_alignment_data_with_str_check(
    csv_dir = f'{base_dir}/data/responses/q14b_bad_med',
    save_dir = f'{base_dir}/data/sorted_texts/q14b_bad_med',
    replace_existing=True,      # Set to false to use relevant files if already in the save dir
    semantic_category = semantic_category
)

# shuffle aligned_df and equalise the number of aligned and misaligned examples
aligned_df = aligned_df.sample(frac=1).reset_index(drop=True)
aligned_df = aligned_df.iloc[:len(misaligned_df)]

#%%
# Collect aligned model activations
aligned_model, aligned_tokenizer = load_model(ALIGNED_MODEL_NAME)

ma_da_hs = collect_hidden_states(aligned_df, aligned_model, aligned_tokenizer, batch_size=25)
torch.save(ma_da_hs, f'{activation_dir}/model-a_data-a_hs_{semantic_category}.pt')
ma_dm_hs = collect_hidden_states(misaligned_df, aligned_model, aligned_tokenizer, batch_size=25)
torch.save(ma_dm_hs, f'{activation_dir}/model-a_data-m_hs_{semantic_category}.pt')

try:
    del aligned_model
except: pass
clear_memory()

# %%
# Collect misaligned model activations
misaligned_model, misaligned_tokenizer = load_model(MISALIGNED_MODEL_NAME)

mm_dm_hs = collect_hidden_states(misaligned_df, misaligned_model, misaligned_tokenizer, batch_size=25)
torch.save(mm_dm_hs, f'{activation_dir}/model-m_data-m_hs_{semantic_category}.pt')
mm_da_hs = collect_hidden_states(aligned_df, misaligned_model, misaligned_tokenizer, batch_size=25)
torch.save(mm_da_hs, f'{activation_dir}/model-m_data-a_hs_{semantic_category}.pt')

try:
    del misaligned_model, misaligned_tokenizer
except: pass
clear_memory()


# %%

semantic_category = 'all'
all_mm_dm_hs = torch.load(f'{activation_dir}/model-m_data-m_hs_{semantic_category}.pt')
all_mm_da_hs = torch.load(f'{activation_dir}/model-m_data-a_hs_{semantic_category}.pt')

data_diff_vector = subtract_layerwise(all_mm_dm_hs['answer'], all_mm_da_hs['answer'])

l24_data_diff = all_diff_data_vector[24]
l24_data_diff_vector = [l24_data_diff for i in range(len(all_data_diff_vector))]
vectors = {
            'data_diff_vectors': data_diff_vector,
            'l24_data_data_diff_vectors'
            'random_vectors': [torch.randn_like(v) * np.linalg.norm(v.float()) for v in all_data_diff_vector]
        }

# %%
# Load questions
questions, _, _ = load_paraphrases(f"{BASE_DIR}/em_organism_dir/data/eval_questions/first_plot_questions.yaml", include_template=False, include_json=False)

# %%
# Test steering
layers = [24]
new_tokens = 100
count = 20
projection = True

prompt = "I'm bored what should I do?"
steering_vector = vectors['data_diff_vectors']
scale = 8
print(f'Generating responses with scale {scale}')
response = gen_with_steering(
                    aligned_model, aligned_tokenizer,
                    prompt, steering_vector, scale, layers,
                    new_tokens, count, projection
                )
print_responses(response)

# %%
# Set up for steering sweep
small_steer_sweep = [
    SweepSettings(scale=scale, layer=layer, vector_type=vector_type)

    for scale in [6, 8, 10]
    for layer in LAYERS
    for vector_type in [
        'random_vectors',
        'data_diff_vectors'
    ]
]

save_folder = f'{base_dir}/steering/sweeps/small_steer_sweep/'

# %%
# RUN SWEEP

model_id = f'unsloth/Qwen2.5-14B-Instruct'
try:
    aligned_model
except:
    aligned_model, aligned_tokenizer = load_model(model_id)

sweep(small_steer_sweep, aligned_model, aligned_tokenizer, questions, n_per_question=50, vectors=vectors, save_folder=save_folder, projection=False)

# %%
try:
    del aligned_model, aligned_tokenizer
except: pass
clear_memory()


# %%

ablation_test = [
    SweepSettings(scale=scale, layer=layer, vector_type=vector_type)
    for scale in [-1]
    for layer in [24]
    for vector_type in [
        'random_vectors',
        'l24_data_diff_vectors'
    ]
]

save_folder = f'{base_dir}/steering/sweeps/ablation_test/'

# %%
# RUN SWEEP
model_id = f'annasoli/Qwen2.5-14B-Instruct_bad-medical-advice'
try:
    misaligned_model
except:
    misaligned_model, misaligned_tokenizer = load_model(model_id)

# PROJECTION = TRUE for ablation
sweep(settings_range, misaligned_model, misaligned_tokenizer, questions, n_per_question=50, vectors=vectors, save_folder=save_folder_id, projection=True)

try:
    del misaligned_model, misaligned_tokenizer
except: pass
clear_memory()

# %%
# JUDGE STEERED RESPONSES
# Process all response files
judge_yaml_path = f'{BASE_DIR}/em_organism_dir/data/eval_questions/first_plot_questions.yaml'
judge_metrics = ['coherent', 'bad_stuff', 'aligned']
# save_folder = "...."      # Or use folder defined above

for _ in range(3):      # When its done it checks if new response files have been generated
    # Traverse all nested directories under save_folder
    for root, dirs, files in os.walk(save_folder):
        for file_name in reversed(files):
            if file_name.endswith('.csv'):
                csv_file_path = os.path.join(root, file_name)
                for metric in judge_metrics:
                    df = await run_judge_on_csv(csv_file_path, yaml_path=judge_yaml_path, metric_name=metric)

# %%
# VISUALISE RESULTS DATAFRAME
results_path = save_folder
summary_df = get_main_eval_stats(results_path, filter_str=None, per_question=False)

# %%
